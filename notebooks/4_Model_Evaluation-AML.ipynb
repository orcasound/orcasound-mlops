{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## If you run this notebook for the first time or you use a new compute instance, you need to install all required libraries. \r\n",
        "You can open the console and use the following commands to install the required python library.\r\n",
        "\r\n",
        "```bash\r\n",
        "pip install -r requirements.txt \r\n",
        "pip install -U torch torchaudio --no-cache-dir\r\n",
        "```\r\n",
        "\r\n",
        "You also need to modify `output_root_folder` varialbe so it align with your intended output data folder path"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import librosa\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import os\r\n",
        "from pathlib import Path\r\n",
        "from tqdm import tqdm\r\n",
        "from sklearn.metrics import recall_score, precision_score, \\\r\n",
        "    f1_score, average_precision_score, precision_recall_curve\r\n",
        "from azureml.core import Workspace, Dataset\r\n",
        "import mlflow\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "# Connect to Workspace and reference Dataset\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1666022460496
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure output folder path. \r\n",
        "\r\n",
        "# ! You need to modify this path to align with your local folder structure becuase it include {user name} here. \r\n",
        "output_root_folder=\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/herman-gpu/code/Users/herman.wu/\"\r\n",
        "ml_experiment_name=\"orca-sound-resnet18-round1to3-FASTAI\"\r\n",
        "model_folder_name=\"models\"\r\n",
        "eval_pred_folder_name=\"eval_pred\"\r\n",
        "final_eval_folder_name=\"final_eval\"\r\n",
        "\r\n",
        "train_dataset_name=\"orcahello-audio-round1to3\"\r\n",
        "test_dataset_name=\"orcahello-audio-testdata-round1to3\"\r\n",
        "benchmark_dataset_name=\"orcahello-audio-perf-benchmark-data\"\r\n",
        "model_eval_test_dataset_name=\"orcahello-model-eval-testdata-01\"\r\n",
        "model_file_name=\"stg2-rn18.pkl\""
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666022840977
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Workspace and reference Dataset\r\n",
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "model_eval_testdataset = ws.datasets[model_eval_test_dataset_name]\r\n",
        "\r\n",
        "# Create mountcontext and mount the dataset\r\n",
        "model_eva_testdata_mount_ctx = model_eval_testdataset.mount()  \r\n",
        "model_eva_testdata_mount_ctx.start()  \r\n",
        "\r\n",
        "# Get the mount point\r\n",
        "test_dataset_mount_folder = model_eva_testdata_mount_ctx.mount_point\r\n",
        "print(test_dataset_mount_folder)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Volume mount is not enabled. \nFalling back to dataflow mount.\n/tmp/tmpdt56g99e\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666022854276
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List the files in the mount point\r\n",
        "files = os.listdir(test_dataset_mount_folder)\r\n",
        "print(files)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['.DS_Store', 'test - Copy.csv', 'test.tsv', 'wav-rpi', 'wav', 'wav2', 'wav3', 'wav4', 'wav5']\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666022858624
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "def quantize_interval_to_seconds(startTime, duration, maxDuration):\r\n",
        "    \"\"\"\r\n",
        "    Returns a list of integers containing corresponding seconds. \r\n",
        "    If second N:N+1 contains part of the interval, N is counted. \r\n",
        "    \"\"\"\r\n",
        "    endTime = startTime + duration\r\n",
        "    low = int(np.floor(startTime))\r\n",
        "    high = min(int(np.ceil(endTime)), int(maxDuration))\r\n",
        "    seconds = list(range(low, high+1))\r\n",
        "    return seconds\r\n",
        "\r\n",
        "def quantize_interval_df(df, startColumn, durationColumn, confColumn, maxDuration, threshold=None):\r\n",
        "    '''\r\n",
        "    Convert given intervals into a 1 second quantized examples for scoring \r\n",
        "    '''\r\n",
        "    df = df.sort_values(startColumn).reset_index(drop=True)\r\n",
        "    timeWindows = []\r\n",
        "    for idx in range(df.shape[0]):\r\n",
        "        startTime = df.loc[idx,startColumn]\r\n",
        "        duration = df.loc[idx,durationColumn]\r\n",
        "        confidence = 1.0 if confColumn is None else df.loc[idx, confColumn]\r\n",
        "        \r\n",
        "        for time_idx in quantize_interval_to_seconds(startTime, duration, maxDuration):\r\n",
        "            timeWindows.append((time_idx, confidence))\r\n",
        "\r\n",
        "    # unique operation merges overlapping windows \r\n",
        "    timeWindows = sorted(list(set(timeWindows)))\r\n",
        "    idxs, confidences = zip(*timeWindows)\r\n",
        "\r\n",
        "    if threshold is None:\r\n",
        "        positiveIdxs = idxs\r\n",
        "    else:\r\n",
        "        positiveIdxs = [tup[0] for tup in timeWindows if tup[1] > threshold]\r\n",
        "    \r\n",
        "    ## Create dataframe quantized into 1-second time windows for scoring \r\n",
        "    quantized_df = pd.DataFrame({\r\n",
        "        'timewindow': range(int(np.ceil(maxDuration))),\r\n",
        "        'label': 0, \r\n",
        "        'confidence': 0.0\r\n",
        "        })\r\n",
        "    quantized_df.loc[positiveIdxs,'label'] = 1\r\n",
        "    quantized_df.loc[idxs,'confidence'] = confidences\r\n",
        "\r\n",
        "    return quantized_df\r\n",
        "\r\n",
        "def score_quantized_examples(dataset, submissionQuantized, groundTruthQuantized, threshold):\r\n",
        "\r\n",
        "    ## Evaluating\r\n",
        "    precision, recall, thresholds = precision_recall_curve(groundTruthQuantized.label, submissionQuantized.confidence)\r\n",
        "    class_prevalence = precision[0]\r\n",
        "\r\n",
        "    metrics = dict()\r\n",
        "    if threshold is not None:\r\n",
        "        metrics['recall'] = round(recall_score(groundTruthQuantized.label, submissionQuantized.label), 3)\r\n",
        "        metrics['precision'] = round(precision_score(groundTruthQuantized.label, submissionQuantized.label), 3)\r\n",
        "        metrics['f1_score'] = round(f1_score(groundTruthQuantized.label, submissionQuantized.label), 3)\r\n",
        "\r\n",
        "    metrics['AUPRC'] = round(average_precision_score(groundTruthQuantized.label, submissionQuantized.confidence), 3)\r\n",
        "\r\n",
        "    auprc_curve = pd.DataFrame(dict(\r\n",
        "        precision=precision,\r\n",
        "        recall=recall,\r\n",
        "        thresholds=[0.0, *thresholds]\r\n",
        "    ))\r\n",
        "    \r\n",
        "    return metrics, auprc_curve, class_prevalence\r\n",
        "\r\n",
        "def score_submission(testSetDir, submissionFile, threshold=None, verbose=False):\r\n",
        "    # load Ground truth and submission \r\n",
        "    testData = pd.read_csv(Path(testSetDir)/\"test.tsv\", delimiter='\\t')\r\n",
        "    testWavDir = Path(testSetDir)/\"wav2\"\r\n",
        "    submissionName = Path(submissionFile).stem\r\n",
        "    # submissionData = pd.read_csv(submissionFile, sep='\\t')\r\n",
        "    submissionData = pd.read_csv(submissionFile)\r\n",
        "\r\n",
        "    # iterate over (test set, wav file) -> aggregate scores appropriately\r\n",
        "    # append for all wav files in a test set and score\r\n",
        "    metrics_list = []\r\n",
        "    auprc_curve_list = []\r\n",
        "    for group in testData.groupby('dataset'):\r\n",
        "        dataset, datasetGroundTruth = group\r\n",
        "\r\n",
        "        print(\"\\n###\\nScoring dataset:\", dataset)\r\n",
        "        gt_list, sub_list = [], []\r\n",
        "        total_duration = 0.0\r\n",
        "        for wavGroup in tqdm(datasetGroundTruth.groupby('wav_filename')):\r\n",
        "            wav_filename, groundTruth = wavGroup\r\n",
        "\r\n",
        "            # retrieve intervals for this group (labels, submission)\r\n",
        "            # TODO@Akash: remove this dependency to require the audio\r\n",
        "            max_length = librosa.get_duration(filename=str(testWavDir/wav_filename))\r\n",
        "            # Convert Ground Truth: HACK doesn't have confidence column, so passing dummy value  \r\n",
        "            gt_list.append(quantize_interval_df(\r\n",
        "                    groundTruth, 'start_time_s', 'duration_s', 'duration_s', max_length\r\n",
        "                ))\r\n",
        "\r\n",
        "            # Quantize submission file into 1-second time windows (timewindow, label, confidence)\r\n",
        "            submission = submissionData.query('wav_filename == @wav_filename')\r\n",
        "            sub_list.append(quantize_interval_df(\r\n",
        "                submission, 'start_time_s', 'duration_s', 'confidence', max_length, threshold=threshold\r\n",
        "                ))\r\n",
        "            \r\n",
        "            total_duration += max_length\r\n",
        "        \r\n",
        "        groundTruthQuantized = pd.concat(gt_list)\r\n",
        "        submissionQuantized = pd.concat(sub_list)\r\n",
        "        print(\"Total duration: {:.0f}:{:.0f}\".format(total_duration//60, total_duration%60))\r\n",
        "        if verbose:\r\n",
        "            print(\"\\nSnippet of converted/quantized ground truth file\\n\", groundTruthQuantized.head(3))\r\n",
        "            print(\"\\nSnippet of converted/quantized submission file\\n\", submissionQuantized.head(3))\r\n",
        "\r\n",
        "        # score and aggregate results \r\n",
        "        metrics, auprc_curve, class_prevalence = score_quantized_examples(\r\n",
        "            dataset, submissionQuantized, groundTruthQuantized, threshold\r\n",
        "            )\r\n",
        "        metrics_list.append({'dataset':dataset, **metrics})\r\n",
        "        auprc_curve['dataset'] = dataset\r\n",
        "        auprc_curve_list.append(auprc_curve)\r\n",
        "    \r\n",
        "    metrics = pd.DataFrame.from_records(metrics_list)\r\n",
        "    overall = metrics.mean(numeric_only=True)\r\n",
        "    overall['dataset'] = 'OVERALL'\r\n",
        "    metrics = metrics.append(overall, ignore_index=True).round(3)\r\n",
        "    \r\n",
        "    return metrics, pd.concat(auprc_curve_list)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666023655576
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submissionFiles=[Path(os.path.join(output_root_folder,eval_pred_folder_name,\"submission2SecFastAI.csv\"))]\r\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666023327226
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for submissionFile in submissionFiles:\r\n",
        "    print(submissionFile)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/herman-gpu/code/Users/herman.wu/eval_pred/submission2SecFastAI.csv\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666022897140
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# metricsFile = Path(submissionFiles[0]).parent/\"metrics.tsv\"\r\n",
        "# resultsFile = Path(submissionFiles[0]).parent/\"results.md\"\r\n",
        "# plotsFile = Path(submissionFiles[0]).parent/\"{}.png\".format(\"au_pr_curves\")\r\n",
        "\r\n",
        "metricsFile = Path(os.path.join(output_root_folder,final_eval_folder_name,\"metrics.tsv\"))\r\n",
        "resultsFile = Path(os.path.join(output_root_folder,final_eval_folder_name,\"results.md\"))\r\n",
        "plotsFile = Path(os.path.join(output_root_folder,final_eval_folder_name,\"au_pr_curves.png\"))"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666022903823
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testSetDir=test_dataset_mount_folder\r\n",
        "threshold=0.8"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666022907110
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(submissionFiles)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/herman-gpu/code/Users/herman.wu/eval_pred/submission2SecFastAI.csv')]\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665419870926
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/herman-gpu/code/Users/herman.wu/eval_pred/\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['.amlignore', '.amlignore.amltmp', 'submission2SecFastAI.csv', 'test2Sec.csv']\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666023344136
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/herman-gpu/code/Users/herman.wu/eval_pred/submission2SecFastAI.csv\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "     StartTime  Duration\n0           21         1\n1           22         1\n2           23         1\n3           51         1\n4           52         1\n..         ...       ...\n511       1201         1\n512       1202         1\n513       1217         1\n514       1218         1\n515       1219         1\n\n[516 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>StartTime</th>\n      <th>Duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>51</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>511</th>\n      <td>1201</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>512</th>\n      <td>1202</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>513</th>\n      <td>1217</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>514</th>\n      <td>1218</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>515</th>\n      <td>1219</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>516 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666023106235
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testSetDir"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "'/tmp/tmpdt56g99e'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666023601165
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testData = pd.read_csv(Path(testSetDir)/\"test.tsv\", delimiter='\\t')"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666025257843
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testData.head(5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "               dataset                wav_filename  start_time_s  duration_s  \\\n0  podcast_test_round1  OS_7_05_2019_08_24_00_.wav        52.172       1.118   \n1  podcast_test_round1  OS_7_05_2019_08_24_00_.wav        54.877       1.104   \n2  podcast_test_round1  OS_7_05_2019_08_24_00_.wav        69.701       2.691   \n3  podcast_test_round1  OS_7_05_2019_08_24_00_.wav        72.765       0.795   \n4  podcast_test_round1  OS_7_05_2019_08_24_00_.wav        73.510       0.925   \n\n        location        date pst_or_master_tape_identifier  \n0  orcasound_lab  1562340736    OS_7_05_2019_08_24_00_.wav  \n1  orcasound_lab  1562340736    OS_7_05_2019_08_24_00_.wav  \n2  orcasound_lab  1562340736    OS_7_05_2019_08_24_00_.wav  \n3  orcasound_lab  1562340736    OS_7_05_2019_08_24_00_.wav  \n4  orcasound_lab  1562340736    OS_7_05_2019_08_24_00_.wav  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>wav_filename</th>\n      <th>start_time_s</th>\n      <th>duration_s</th>\n      <th>location</th>\n      <th>date</th>\n      <th>pst_or_master_tape_identifier</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>podcast_test_round1</td>\n      <td>OS_7_05_2019_08_24_00_.wav</td>\n      <td>52.172</td>\n      <td>1.118</td>\n      <td>orcasound_lab</td>\n      <td>1562340736</td>\n      <td>OS_7_05_2019_08_24_00_.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>podcast_test_round1</td>\n      <td>OS_7_05_2019_08_24_00_.wav</td>\n      <td>54.877</td>\n      <td>1.104</td>\n      <td>orcasound_lab</td>\n      <td>1562340736</td>\n      <td>OS_7_05_2019_08_24_00_.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>podcast_test_round1</td>\n      <td>OS_7_05_2019_08_24_00_.wav</td>\n      <td>69.701</td>\n      <td>2.691</td>\n      <td>orcasound_lab</td>\n      <td>1562340736</td>\n      <td>OS_7_05_2019_08_24_00_.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>podcast_test_round1</td>\n      <td>OS_7_05_2019_08_24_00_.wav</td>\n      <td>72.765</td>\n      <td>0.795</td>\n      <td>orcasound_lab</td>\n      <td>1562340736</td>\n      <td>OS_7_05_2019_08_24_00_.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>podcast_test_round1</td>\n      <td>OS_7_05_2019_08_24_00_.wav</td>\n      <td>73.510</td>\n      <td>0.925</td>\n      <td>orcasound_lab</td>\n      <td>1562340736</td>\n      <td>OS_7_05_2019_08_24_00_.wav</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666025271896
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " for group in testData.groupby('dataset'):\r\n",
        "        dataset, datasetGroundTruth = group\r\n",
        "\r\n",
        "        print(\"\\n###\\nScoring dataset:\", dataset)\r\n",
        "        gt_list, sub_list = [], []\r\n",
        "        total_duration = 0.0\r\n",
        "        for wavGroup in tqdm(datasetGroundTruth.groupby('wav_filename')):\r\n",
        "            wav_filename, groundTruth = wavGroup\r\n",
        "            print(wav_filename)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n###\nScoring dataset: podcast_test_round1\nOS_7_05_2019_08_24_00_.wav\n\n###\nScoring dataset: podcast_test_round2\nOS_9_27_2017_08_14_00__0001.wav\nOS_9_27_2017_08_19_00__0002.wav\nOS_9_27_2017_08_25_00__0003.wav\nOS_9_27_2017_08_25_00__0004.wav\nOS_9_27_2017_08_30_00__0001.wav\nOS_9_27_2017_08_30_00__0002.wav\nOS_9_27_2017_08_30_00__0003.wav\nOS_9_27_2017_08_35_00__0004.wav\nOS_9_27_2017_09_02_00__0002.wav\nOS_9_27_2017_09_34_00__0002.wav\nOS_9_27_2017_10_28_00__0001.wav\nOS_9_27_2017_10_49_00__0003.wav\nOS_9_27_2017_11_00_00__0004.wav\nOS_9_27_2017_11_05_00__0000.wav\nOS_9_27_2017_11_26_00__0000.wav\nOS_9_27_2017_11_26_00__0002.wav\nOS_9_27_2017_11_32_00__0002.wav\nOS_9_27_2017_11_32_00__0003.wav\nOS_9_27_2017_11_42_00__0000.wav\nOS_9_27_2017_11_53_00__0001.wav\nOS_9_27_2017_11_58_00__0003.wav\n\n###\nScoring dataset: podcast_test_round3\nrpi-port-townsend_2019_11_14_12_33_00.wav\nrpi-port-townsend_2019_11_14_12_34_00.wav\nrpi-port-townsend_2019_11_14_12_47_00.wav\nrpi-port-townsend_2019_11_14_12_48_00.wav\nrpi-port-townsend_2019_11_14_12_49_00.wav\nrpi-port-townsend_2019_11_14_14_11_00.wav\nrpi-port-townsend_2019_11_14_14_15_00.wav\nrpi-port-townsend_2019_11_14_14_27_00.wav\nrpi-port-townsend_2019_11_14_14_28_00.wav\nrpi-port-townsend_2019_11_14_14_29_00.wav\nstreaming-orcasound-net_2019_11_14_12_50_00.wav\nstreaming-orcasound-net_2019_11_14_12_51_00.wav\nstreaming-orcasound-net_2019_11_14_12_52_00.wav\nstreaming-orcasound-net_2019_11_14_12_53_00.wav\nstreaming-orcasound-net_2019_11_14_12_54_00.wav\nstreaming-orcasound-net_2019_11_14_12_55_00.wav\nstreaming-orcasound-net_2019_11_14_12_56_00.wav\nstreaming-orcasound-net_2019_11_14_12_57_00.wav\nstreaming-orcasound-net_2019_11_14_12_58_00.wav\nstreaming-orcasound-net_2019_11_14_12_59_00.wav\nstreaming-orcasound-net_2019_11_14_13_00_00.wav\nstreaming-orcasound-net_2019_11_14_13_01_00.wav\nstreaming-orcasound-net_2019_11_14_13_02_00.wav\nstreaming-orcasound-net_2019_11_14_13_03_00.wav\nstreaming-orcasound-net_2019_11_14_13_04_00.wav\nstreaming-orcasound-net_2019_11_14_13_05_00.wav\nstreaming-orcasound-net_2019_11_14_13_06_00.wav\nstreaming-orcasound-net_2019_11_14_13_07_00.wav\nstreaming-orcasound-net_2019_11_14_13_08_00.wav\nstreaming-orcasound-net_2019_11_14_13_09_00.wav\nstreaming-orcasound-net_2019_11_14_13_10_00.wav\nstreaming-orcasound-net_2019_11_14_13_11_00.wav\nstreaming-orcasound-net_2019_11_14_13_12_00.wav\nstreaming-orcasound-net_2019_11_14_13_13_00.wav\nstreaming-orcasound-net_2019_11_14_13_14_00.wav\nstreaming-orcasound-net_2019_11_14_13_15_00.wav\nstreaming-orcasound-net_2019_11_14_13_16_00.wav\nstreaming-orcasound-net_2019_11_14_13_17_00.wav\nstreaming-orcasound-net_2019_11_14_13_18_00.wav\nstreaming-orcasound-net_2019_11_14_13_19_00.wav\nstreaming-orcasound-net_2019_11_14_13_20_00.wav\nstreaming-orcasound-net_2019_11_14_13_21_00.wav\nstreaming-orcasound-net_2019_11_14_13_22_00.wav\nstreaming-orcasound-net_2019_11_14_13_23_00.wav\nstreaming-orcasound-net_2019_11_14_13_24_00.wav\nstreaming-orcasound-net_2019_11_14_13_25_00.wav\nstreaming-orcasound-net_2019_11_14_13_26_00.wav\nstreaming-orcasound-net_2019_11_14_13_27_00.wav\nstreaming-orcasound-net_2019_11_14_13_28_00.wav\nstreaming-orcasound-net_2019_11_14_13_29_00.wav\nstreaming-orcasound-net_2019_11_14_13_30_00.wav\nstreaming-orcasound-net_2019_11_14_13_31_00.wav\nstreaming-orcasound-net_2019_11_14_13_32_00.wav\nstreaming-orcasound-net_2019_11_14_13_33_00.wav\nstreaming-orcasound-net_2019_11_14_13_34_00.wav\nstreaming-orcasound-net_2019_11_14_13_35_00.wav\nstreaming-orcasound-net_2019_11_14_13_36_00.wav\nstreaming-orcasound-net_2019_11_14_13_37_00.wav\nstreaming-orcasound-net_2019_11_14_13_38_00.wav\nstreaming-orcasound-net_2019_11_14_13_39_00.wav\nstreaming-orcasound-net_2019_11_14_13_40_00.wav\nstreaming-orcasound-net_2019_11_14_13_41_00.wav\nstreaming-orcasound-net_2019_11_14_13_42_00.wav\nstreaming-orcasound-net_2019_11_14_13_43_00.wav\nstreaming-orcasound-net_2019_11_14_13_44_00.wav\nstreaming-orcasound-net_2019_11_14_13_45_00.wav\nstreaming-orcasound-net_2019_11_14_13_46_00.wav\nstreaming-orcasound-net_2019_11_14_13_47_00.wav\nstreaming-orcasound-net_2019_11_14_13_48_00.wav\nstreaming-orcasound-net_2019_11_14_13_49_00.wav\nstreaming-orcasound-net_2019_11_14_13_50_00.wav\nstreaming-orcasound-net_2019_11_14_13_51_00.wav\nstreaming-orcasound-net_2019_11_14_13_52_00.wav\nstreaming-orcasound-net_2019_11_14_13_53_00.wav\nstreaming-orcasound-net_2019_11_14_13_54_00.wav\nstreaming-orcasound-net_2019_11_14_13_55_00.wav\nstreaming-orcasound-net_2019_11_14_13_56_00.wav\nstreaming-orcasound-net_2019_11_14_13_57_00.wav\nstreaming-orcasound-net_2019_11_14_13_58_00.wav\nstreaming-orcasound-net_2019_11_14_13_59_00.wav\nstreaming-orcasound-net_2019_11_14_14_00_00.wav\nstreaming-orcasound-net_2019_11_14_14_01_00.wav\nstreaming-orcasound-net_2019_11_14_14_02_00.wav\nstreaming-orcasound-net_2019_11_14_14_03_00.wav\nstreaming-orcasound-net_2019_11_14_14_04_00.wav\nstreaming-orcasound-net_2019_11_14_14_05_00.wav\nstreaming-orcasound-net_2019_11_14_14_06_00.wav\nstreaming-orcasound-net_2019_11_14_14_07_00.wav\nstreaming-orcasound-net_2019_11_14_14_08_00.wav\nstreaming-orcasound-net_2019_11_14_14_09_00.wav\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666025857465
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submissionData = pd.read_csv(submissionFile)\r\n",
        "submissionData.head(5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "   StartTime  Duration\n0         21         1\n1         22         1\n2         23         1\n3         51         1\n4         52         1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>StartTime</th>\n      <th>Duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>51</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666025998258
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " for group in testData.groupby('dataset'):\r\n",
        "        dataset, datasetGroundTruth = group\r\n",
        "\r\n",
        "        print(\"\\n###\\nScoring dataset:\", dataset)\r\n",
        "        gt_list, sub_list = [], []\r\n",
        "        total_duration = 0.0\r\n",
        "        for wavGroup in tqdm(datasetGroundTruth.groupby('wav_filename')):\r\n",
        "            wav_filename, groundTruth = wavGroup\r\n",
        "\r\n",
        "            # retrieve intervals for this group (labels, submission)\r\n",
        "            # TODO@Akash: remove this dependency to require the audio\r\n",
        "            max_length = librosa.get_duration(filename=str(testWavDir/wav_filename))\r\n",
        "            # Convert Ground Truth: HACK doesn't have confidence column, so passing dummy value  \r\n",
        "            gt_list.append(quantize_interval_df(\r\n",
        "                    groundTruth, 'start_time_s', 'duration_s', 'duration_s', max_length\r\n",
        "                ))\r\n",
        "\r\n",
        "            # Quantize submission file into 1-second time windows (timewindow, label, confidence)\r\n",
        "            submission = submissionData.query('wav_filename == @wav_filename')\r\n",
        "            sub_list.append(quantize_interval_df(\r\n",
        "                submission, 'start_time_s', 'duration_s', 'confidence', max_length, threshold=threshold\r\n",
        "                ))\r\n",
        "            "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scoring multiple submission files \r\n",
        "metrics_list, auprc_list = [], []\r\n",
        "for submissionFile in submissionFiles:\r\n",
        "    print(submissionFile)\r\n",
        "    metrics, auprc_curve = score_submission(testSetDir, submissionFile, threshold)\r\n",
        "    # TODO@Akash: include class prevalence as a \"no-skill\" submission \r\n",
        "    metrics['submission'] = Path(submissionFile).stem\r\n",
        "    metrics_list.append(metrics)\r\n",
        "    auprc_curve['submission'] = Path(submissionFile).stem\r\n",
        "    auprc_list.append(auprc_curve)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/herman-gpu/code/Users/herman.wu/eval_pred/submission2SecFastAI.csv\n\n###\nScoring dataset: podcast_test_round1\n"
        },
        {
          "output_type": "error",
          "ename": "UndefinedVariableError",
          "evalue": "name 'wav_filename' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/scope.py:188\u001b[0m, in \u001b[0;36mScope.resolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_resolvers:\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolvers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# if we're here that means that we have no locals and we also have\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# no resolvers\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/collections/__init__.py:898\u001b[0m, in \u001b[0;36mChainMap.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__missing__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/collections/__init__.py:890\u001b[0m, in \u001b[0;36mChainMap.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__missing__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'wav_filename'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/scope.py:199\u001b[0m, in \u001b[0;36mScope.resolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# last ditch effort we look in temporaries\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# these are created when parsing indexing expressions\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# e.g., df[df > 0]\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# runtime import because ops imports from scope\u001b[39;00m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'wav_filename'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mUndefinedVariableError\u001b[0m                    Traceback (most recent call last)",
            "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m submissionFile \u001b[38;5;129;01min\u001b[39;00m submissionFiles:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(submissionFile)\n\u001b[0;32m----> 5\u001b[0m     metrics, auprc_curve \u001b[38;5;241m=\u001b[39m \u001b[43mscore_submission\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestSetDir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmissionFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# TODO@Akash: include class prevalence as a \"no-skill\" submission \u001b[39;00m\n\u001b[1;32m      7\u001b[0m     metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Path(submissionFile)\u001b[38;5;241m.\u001b[39mstem\n",
            "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mscore_submission\u001b[0;34m(testSetDir, submissionFile, threshold, verbose)\u001b[0m\n\u001b[1;32m     93\u001b[0m gt_list\u001b[38;5;241m.\u001b[39mappend(quantize_interval_df(\n\u001b[1;32m     94\u001b[0m         groundTruth, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time_s\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration_s\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration_s\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length\n\u001b[1;32m     95\u001b[0m     ))\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Quantize submission file into 1-second time windows (timewindow, label, confidence)\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m submission \u001b[38;5;241m=\u001b[39m \u001b[43msubmissionData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwav_filename == @wav_filename\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m sub_list\u001b[38;5;241m.\u001b[39mappend(quantize_interval_df(\n\u001b[1;32m    100\u001b[0m     submission, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time_s\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration_s\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length, threshold\u001b[38;5;241m=\u001b[39mthreshold\n\u001b[1;32m    101\u001b[0m     ))\n\u001b[1;32m    103\u001b[0m total_duration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m max_length\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/frame.py:3345\u001b[0m, in \u001b[0;36mDataFrame.query\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   3343\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3344\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3345\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3348\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[res]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/frame.py:3475\u001b[0m, in \u001b[0;36mDataFrame.eval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   3472\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   3473\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolvers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolvers\u001b[39m\u001b[38;5;124m\"\u001b[39m, ()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(resolvers)\n\u001b[0;32m-> 3475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/eval.py:341\u001b[0m, in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# get our (possibly passed-in) scope\u001b[39;00m\n\u001b[1;32m    333\u001b[0m env \u001b[38;5;241m=\u001b[39m ensure_scope(\n\u001b[1;32m    334\u001b[0m     level \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    335\u001b[0m     global_dict\u001b[38;5;241m=\u001b[39mglobal_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    339\u001b[0m )\n\u001b[0;32m--> 341\u001b[0m parsed_expr \u001b[38;5;241m=\u001b[39m \u001b[43mExpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# construct the engine and evaluate the parsed expression\u001b[39;00m\n\u001b[1;32m    344\u001b[0m eng \u001b[38;5;241m=\u001b[39m _engines[engine]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:787\u001b[0m, in \u001b[0;36mExpr.__init__\u001b[0;34m(self, expr, engine, parser, env, level)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m parser\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visitor \u001b[38;5;241m=\u001b[39m _parsers[parser](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser)\n\u001b[0;32m--> 787\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:806\u001b[0m, in \u001b[0;36mExpr.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    Parse an expression.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_visitor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:398\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    397\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:404\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Module\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly a single expression is allowed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    403\u001b[0m expr \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mbody[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:398\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    397\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:407\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Expr\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit_Expr\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:398\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    397\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:699\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Compare\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslate_In(ops[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    698\u001b[0m     binop \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mBinOp(op\u001b[38;5;241m=\u001b[39mop, left\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39mleft, right\u001b[38;5;241m=\u001b[39mcomps[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;66;03m# recursive case: we have a chained comparison, a CMP b CMP c, etc.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m left \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mleft\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:398\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    397\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:520\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_BinOp\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit_BinOp\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 520\u001b[0m     op, op_class, left, right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_transform_eq_ne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m     left, right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_downcast_constants(left, right)\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_evaluate_binop(op, op_class, left, right)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:439\u001b[0m, in \u001b[0;36mBaseExprVisitor._maybe_transform_eq_ne\u001b[0;34m(self, node, left, right)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_transform_eq_ne\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, left\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, right\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m         right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisit(node\u001b[38;5;241m.\u001b[39mright, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:398\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    397\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/expr.py:533\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Name\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit_Name\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterm_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/ops.py:84\u001b[0m, in \u001b[0;36mTerm.__init__\u001b[0;34m(self, name, env, side, encoding)\u001b[0m\n\u001b[1;32m     82\u001b[0m tname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(name)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_local \u001b[38;5;241m=\u001b[39m tname\u001b[38;5;241m.\u001b[39mstartswith(_LOCAL_TAG) \u001b[38;5;129;01mor\u001b[39;00m tname \u001b[38;5;129;01min\u001b[39;00m _DEFAULT_GLOBALS\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;241m=\u001b[39m encoding\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/ops.py:101\u001b[0m, in \u001b[0;36mTerm._resolve_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resolve_name\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 101\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(res)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m res\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/computation/scope.py:204\u001b[0m, in \u001b[0;36mScope.resolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# runtime import because ops imports from scope\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UndefinedVariableError\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UndefinedVariableError(key, is_local) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
            "\u001b[0;31mUndefinedVariableError\u001b[0m: name 'wav_filename' is not defined"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666023675798
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /tmp/tmpdt56g99e/wav2"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OS_7_05_2019_08_24_00_.wav\r\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /tmp/tmpdt56g99e/wav"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OS_9_27_2017_08_14_00__0001.wav  OS_9_27_2017_10_49_00__0003.wav\r\nOS_9_27_2017_08_19_00__0002.wav  OS_9_27_2017_11_00_00__0004.wav\r\nOS_9_27_2017_08_25_00__0003.wav  OS_9_27_2017_11_05_00__0000.wav\r\nOS_9_27_2017_08_25_00__0004.wav  OS_9_27_2017_11_26_00__0000.wav\r\nOS_9_27_2017_08_30_00__0001.wav  OS_9_27_2017_11_26_00__0002.wav\r\nOS_9_27_2017_08_30_00__0002.wav  OS_9_27_2017_11_32_00__0002.wav\r\nOS_9_27_2017_08_30_00__0003.wav  OS_9_27_2017_11_32_00__0003.wav\r\nOS_9_27_2017_08_35_00__0004.wav  OS_9_27_2017_11_42_00__0000.wav\r\nOS_9_27_2017_09_02_00__0002.wav  OS_9_27_2017_11_53_00__0001.wav\r\nOS_9_27_2017_09_34_00__0002.wav  OS_9_27_2017_11_58_00__0003.wav\r\nOS_9_27_2017_10_28_00__0001.wav\r\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.concat(metrics_list)\r\n",
        "metrics.to_csv(metricsFile, sep='\\t', index=False)\r\n",
        "print(\"Metrics written to\", metricsFile)\r\n",
        "print(metrics.set_index(['submission', 'dataset']))\r\n",
        "metrics_table = metrics.pivot(index='dataset', columns='submission', values='AUPRC')\r\n",
        "with open(resultsFile, 'w') as f:\r\n",
        "    f.write(metrics_table.to_markdown())\r\n",
        "    print(\"Results summary written to\", resultsFile)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregate and compile results from different submission files \r\n",
        "auprc_curve = pd.concat(auprc_list)\r\n",
        "p = sns.FacetGrid(data=auprc_curve, col='dataset', row='submission', margin_titles=True)\r\n",
        "p.map(sns.lineplot, 'recall', 'precision')\r\n",
        "p.set(ylim=(0.,1.0))\r\n",
        "p.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\r\n",
        "plt.savefig(plotsFile)\r\n",
        "print(\"Precision-Recall plots written to\", plotsFile)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument('-testSetDir', default=None, type=str, required=True)\r\n",
        "    parser.add_argument('-submissionFiles', default=None, type=str, required=True)\r\n",
        "    parser.add_argument('-threshold', default=None, type=float, required=False)\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    submissionFiles = args.submissionFiles.split(',')\r\n",
        "    metricsFile = Path(submissionFiles[0]).parent/\"metrics.tsv\"\r\n",
        "    resultsFile = Path(submissionFiles[0]).parent/\"results.md\"\r\n",
        "    plotsFile = Path(submissionFiles[0]).parent/\"{}.png\".format(\"au_pr_curves\")\r\n",
        "\r\n",
        "    # scoring multiple submission files \r\n",
        "    metrics_list, auprc_list = [], []\r\n",
        "    for submissionFile in submissionFiles:\r\n",
        "        metrics, auprc_curve = score_submission(args.testSetDir, submissionFile, args.threshold)\r\n",
        "        # TODO@Akash: include class prevalence as a \"no-skill\" submission \r\n",
        "        metrics['submission'] = Path(submissionFile).stem\r\n",
        "        metrics_list.append(metrics)\r\n",
        "        auprc_curve['submission'] = Path(submissionFile).stem\r\n",
        "        auprc_list.append(auprc_curve)\r\n",
        "    \r\n",
        "    metrics = pd.concat(metrics_list)\r\n",
        "    metrics.to_csv(metricsFile, sep='\\t', index=False)\r\n",
        "    print(\"Metrics written to\", metricsFile)\r\n",
        "    print(metrics.set_index(['submission', 'dataset']))\r\n",
        "    metrics_table = metrics.pivot(index='dataset', columns='submission', values='AUPRC')\r\n",
        "    with open(resultsFile, 'w') as f:\r\n",
        "        f.write(metrics_table.to_markdown())\r\n",
        "        print(\"Results summary written to\", resultsFile)\r\n",
        "    \r\n",
        "    # aggregate and compile results from different submission files \r\n",
        "    auprc_curve = pd.concat(auprc_list)\r\n",
        "    p = sns.FacetGrid(data=auprc_curve, col='dataset', row='submission', margin_titles=True)\r\n",
        "    p.map(sns.lineplot, 'recall', 'precision')\r\n",
        "    p.set(ylim=(0.,1.0))\r\n",
        "    p.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\r\n",
        "    plt.savefig(plotsFile)\r\n",
        "    print(\"Precision-Recall plots written to\", plotsFile)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}